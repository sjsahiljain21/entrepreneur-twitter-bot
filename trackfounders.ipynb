{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rapidfuzz\n",
    "# pip install gspread-dataframe\n",
    "# pip install pandas\n",
    "# pip install lxml\n",
    "# pip install tweepy\n",
    "# pip install gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import gspread\n",
    "import gspread_dataframe as gd\n",
    "import rapidfuzz.fuzz as fuzz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(id):\n",
    "\n",
    "    all_tweets = []\n",
    "    for response in tweepy.Paginator(client.get_users_tweets,\n",
    "                                    id = f\"{id}\",\n",
    "                                    exclude=\"retweets\",\n",
    "                                    user_fields = ['username', 'public_metrics'],\n",
    "                                    tweet_fields = ['created_at', 'public_metrics', 'text'],\n",
    "                                    expansions = ['author_id', 'referenced_tweets.id'],\n",
    "                                    start_time = (datetime.today() - timedelta(days=10)).isoformat()[0:-7]+\"Z\",\n",
    "                                    # end_time = '2022-03-19T00:00:01Z',\n",
    "                                    max_results=100):\n",
    "        time.sleep(1)\n",
    "        all_tweets.append(response)\n",
    "    \n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets_info(all_tweets):\n",
    "\n",
    "    result = []\n",
    "    user_dict = {}\n",
    "    # Loop through each response object\n",
    "    for response in all_tweets:\n",
    "        # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "        for user in response.includes['users']:\n",
    "            user_dict[user.id] = {'username': user.username, \n",
    "                                'followers': user.public_metrics['followers_count'],\n",
    "                                'tweets': user.public_metrics['tweet_count'],\n",
    "                                'description': user.description,\n",
    "                                'location': user.location\n",
    "                                }\n",
    "                                        \n",
    "        for tweet in response.data:\n",
    "            # For each tweet, find the author's information\n",
    "            author_info = user_dict[tweet.author_id]\n",
    "\n",
    "            try:\n",
    "                reference_status = tweet.referenced_tweets[0].type\n",
    "            except:\n",
    "                reference_status = None\n",
    "            \n",
    "            # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "            result.append({'author_id': tweet.author_id, \n",
    "                        'username': author_info['username'],\n",
    "                        'author_followers': author_info['followers'],\n",
    "                        'author_tweets': author_info['tweets'],\n",
    "                        'author_description': author_info['description'],\n",
    "                        'author_location': author_info['location'],\n",
    "                        'text': tweet.text,\n",
    "                        'created_at': tweet.created_at,\n",
    "                        'retweets': tweet.public_metrics['retweet_count'],\n",
    "                        'replies': tweet.public_metrics['reply_count'],\n",
    "                        'likes': tweet.public_metrics['like_count'],\n",
    "                        'quote_count': tweet.public_metrics['quote_count'],\n",
    "                        'tweet_id': tweet.id,        \n",
    "                        'reference_status': reference_status\n",
    "                        })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = os.environ['consumer_key']\n",
    "consumer_secret = os.environ['consumer_secret']\n",
    "access_token = os.environ['access_token']\n",
    "access_token_secret = os.environ['access_token_secret']\n",
    "bearer_token = os.environ['bearer_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=bearer_token, consumer_key=consumer_key, consumer_secret=consumer_secret, access_token=access_token, access_token_secret=access_token_secret, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShivAroor</th>\n",
       "      <th>ShekharGupta</th>\n",
       "      <th>captriturathee</th>\n",
       "      <th>ashutosh83B</th>\n",
       "      <th>kunalb11</th>\n",
       "      <th>supriyapaul93</th>\n",
       "      <th>deepigoyal</th>\n",
       "      <th>viraj_sheth</th>\n",
       "      <th>bhash</th>\n",
       "      <th>vijayshekhar</th>\n",
       "      <th>...</th>\n",
       "      <th>rohitkbansal</th>\n",
       "      <th>Chikisarkar</th>\n",
       "      <th>ashishkashyap</th>\n",
       "      <th>kavinbm</th>\n",
       "      <th>harshilmathur</th>\n",
       "      <th>telljeeves</th>\n",
       "      <th>AnshulSushil</th>\n",
       "      <th>Aakriti</th>\n",
       "      <th>GabbbarSingh</th>\n",
       "      <th>Being_Humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manujosephsan</td>\n",
       "      <td>ELuttwak</td>\n",
       "      <td>jsaideepak</td>\n",
       "      <td>AnupamConnects</td>\n",
       "      <td>stephsmithio</td>\n",
       "      <td>adadithya</td>\n",
       "      <td>IRONMANtri</td>\n",
       "      <td>_buildd</td>\n",
       "      <td>CNBCTV18Live</td>\n",
       "      <td>maheshperi</td>\n",
       "      <td>...</td>\n",
       "      <td>naval</td>\n",
       "      <td>bridgerton</td>\n",
       "      <td>AyushkWadhwa</td>\n",
       "      <td>sayinshallah</td>\n",
       "      <td>zacliew</td>\n",
       "      <td>chennamaneni</td>\n",
       "      <td>yamini_bhat</td>\n",
       "      <td>pheadrick</td>\n",
       "      <td>Being_Humor</td>\n",
       "      <td>LegalTalwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joe_sameer</td>\n",
       "      <td>carlbildt</td>\n",
       "      <td>SadiqAl55350795</td>\n",
       "      <td>rajinikanth</td>\n",
       "      <td>shitPM</td>\n",
       "      <td>BeriArpit</td>\n",
       "      <td>deepdbhandari</td>\n",
       "      <td>vandana_menon</td>\n",
       "      <td>CNBCTV18News</td>\n",
       "      <td>NeinQuarterly</td>\n",
       "      <td>...</td>\n",
       "      <td>SnapdealGujarat</td>\n",
       "      <td>orangeturban</td>\n",
       "      <td>duatweets</td>\n",
       "      <td>gregjoz</td>\n",
       "      <td>stevekucia</td>\n",
       "      <td>shantanukd</td>\n",
       "      <td>anusehgal</td>\n",
       "      <td>KhadimBatti</td>\n",
       "      <td>vasudev_ravi</td>\n",
       "      <td>SouravArts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KumarKunalmedia</td>\n",
       "      <td>IAPonomarenko</td>\n",
       "      <td>Neeraj_chopra1</td>\n",
       "      <td>SenseandC_sense</td>\n",
       "      <td>DmytroKuleba</td>\n",
       "      <td>abhisheknag</td>\n",
       "      <td>AnilSinghvi_</td>\n",
       "      <td>satyan</td>\n",
       "      <td>AionicsInc</td>\n",
       "      <td>TeamBlind</td>\n",
       "      <td>...</td>\n",
       "      <td>fafsters</td>\n",
       "      <td>Karlwheel</td>\n",
       "      <td>GitaGopinath</td>\n",
       "      <td>_Kaspar__</td>\n",
       "      <td>Tejasvi_Surya</td>\n",
       "      <td>rahulrmv</td>\n",
       "      <td>anupohaney</td>\n",
       "      <td>AnishaPatnaik</td>\n",
       "      <td>JohnHulsman1</td>\n",
       "      <td>kaykaymenon02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AxisMyIndia</td>\n",
       "      <td>BinaShah</td>\n",
       "      <td>iamsrk</td>\n",
       "      <td>samajwadiparty</td>\n",
       "      <td>SahilBloom</td>\n",
       "      <td>pratshukla</td>\n",
       "      <td>UltrahumanHQ</td>\n",
       "      <td>PoddarNisha</td>\n",
       "      <td>yurimilner</td>\n",
       "      <td>gauravg85</td>\n",
       "      <td>...</td>\n",
       "      <td>mrgirish</td>\n",
       "      <td>ptrmadurai</td>\n",
       "      <td>anuhyaprayaga</td>\n",
       "      <td>Fwiz</td>\n",
       "      <td>kiranshaw</td>\n",
       "      <td>DeepikaDakuda</td>\n",
       "      <td>jagora</td>\n",
       "      <td>AiyyoShraddha</td>\n",
       "      <td>ClintEhrlich</td>\n",
       "      <td>MattLaemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ItsShubhangi</td>\n",
       "      <td>KyivIndependent</td>\n",
       "      <td>ShishirGoUP</td>\n",
       "      <td>puru_ag</td>\n",
       "      <td>McConaughey</td>\n",
       "      <td>MohapatraHemant</td>\n",
       "      <td>vatsalsinghal</td>\n",
       "      <td>Ashneer_Grover</td>\n",
       "      <td>harari_yuval</td>\n",
       "      <td>NetaFlixIndia</td>\n",
       "      <td>...</td>\n",
       "      <td>geneliad</td>\n",
       "      <td>devangshudatta</td>\n",
       "      <td>udaykotak</td>\n",
       "      <td>AdamMGrant</td>\n",
       "      <td>thetanmay</td>\n",
       "      <td>ManishaRaisingh</td>\n",
       "      <td>Priyamouli1812</td>\n",
       "      <td>bhavintu</td>\n",
       "      <td>W7VOA</td>\n",
       "      <td>GabbbarSingh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3935 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ShivAroor     ShekharGupta   captriturathee      ashutosh83B  \\\n",
       "0       manujosephsan         ELuttwak       jsaideepak   AnupamConnects   \n",
       "1          joe_sameer        carlbildt  SadiqAl55350795      rajinikanth   \n",
       "2     KumarKunalmedia    IAPonomarenko   Neeraj_chopra1  SenseandC_sense   \n",
       "3         AxisMyIndia         BinaShah           iamsrk   samajwadiparty   \n",
       "4        ItsShubhangi  KyivIndependent      ShishirGoUP          puru_ag   \n",
       "...               ...              ...              ...              ...   \n",
       "3930              NaN              NaN              NaN              NaN   \n",
       "3931              NaN              NaN              NaN              NaN   \n",
       "3932              NaN              NaN              NaN              NaN   \n",
       "3933              NaN              NaN              NaN              NaN   \n",
       "3934              NaN              NaN              NaN              NaN   \n",
       "\n",
       "          kunalb11    supriyapaul93     deepigoyal     viraj_sheth  \\\n",
       "0     stephsmithio        adadithya     IRONMANtri         _buildd   \n",
       "1           shitPM        BeriArpit  deepdbhandari   vandana_menon   \n",
       "2     DmytroKuleba      abhisheknag   AnilSinghvi_          satyan   \n",
       "3       SahilBloom       pratshukla   UltrahumanHQ     PoddarNisha   \n",
       "4      McConaughey  MohapatraHemant  vatsalsinghal  Ashneer_Grover   \n",
       "...            ...              ...            ...             ...   \n",
       "3930           NaN              NaN            NaN             NaN   \n",
       "3931           NaN              NaN            NaN             NaN   \n",
       "3932           NaN              NaN            NaN             NaN   \n",
       "3933           NaN              NaN            NaN             NaN   \n",
       "3934           NaN              NaN            NaN             NaN   \n",
       "\n",
       "             bhash   vijayshekhar  ...     rohitkbansal     Chikisarkar  \\\n",
       "0     CNBCTV18Live     maheshperi  ...            naval      bridgerton   \n",
       "1     CNBCTV18News  NeinQuarterly  ...  SnapdealGujarat    orangeturban   \n",
       "2       AionicsInc      TeamBlind  ...         fafsters       Karlwheel   \n",
       "3       yurimilner      gauravg85  ...         mrgirish      ptrmadurai   \n",
       "4     harari_yuval  NetaFlixIndia  ...         geneliad  devangshudatta   \n",
       "...            ...            ...  ...              ...             ...   \n",
       "3930           NaN            NaN  ...              NaN             NaN   \n",
       "3931           NaN            NaN  ...              NaN             NaN   \n",
       "3932           NaN            NaN  ...              NaN             NaN   \n",
       "3933           NaN            NaN  ...              NaN             NaN   \n",
       "3934           NaN            NaN  ...              NaN             NaN   \n",
       "\n",
       "      ashishkashyap       kavinbm  harshilmathur       telljeeves  \\\n",
       "0      AyushkWadhwa  sayinshallah        zacliew     chennamaneni   \n",
       "1         duatweets       gregjoz     stevekucia       shantanukd   \n",
       "2      GitaGopinath     _Kaspar__  Tejasvi_Surya         rahulrmv   \n",
       "3     anuhyaprayaga          Fwiz      kiranshaw    DeepikaDakuda   \n",
       "4         udaykotak    AdamMGrant      thetanmay  ManishaRaisingh   \n",
       "...             ...           ...            ...              ...   \n",
       "3930            NaN           NaN            NaN              NaN   \n",
       "3931            NaN           NaN            NaN              NaN   \n",
       "3932            NaN           NaN            NaN              NaN   \n",
       "3933            NaN           NaN            NaN              NaN   \n",
       "3934            NaN           NaN            NaN              NaN   \n",
       "\n",
       "        AnshulSushil        Aakriti  GabbbarSingh    Being_Humor  \n",
       "0        yamini_bhat      pheadrick   Being_Humor    LegalTalwar  \n",
       "1          anusehgal    KhadimBatti  vasudev_ravi     SouravArts  \n",
       "2         anupohaney  AnishaPatnaik  JohnHulsman1  kaykaymenon02  \n",
       "3             jagora  AiyyoShraddha  ClintEhrlich     MattLaemon  \n",
       "4     Priyamouli1812       bhavintu         W7VOA   GabbbarSingh  \n",
       "...              ...            ...           ...            ...  \n",
       "3930             NaN            NaN           NaN            NaN  \n",
       "3931             NaN            NaN           NaN            NaN  \n",
       "3932             NaN            NaN           NaN            NaN  \n",
       "3933             NaN            NaN           NaN            NaN  \n",
       "3934             NaN            NaN           NaN            NaN  \n",
       "\n",
       "[3935 rows x 34 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gspread.service_account(filename='creds.json')\n",
    "ws = gc.open(\"trackfounders\").worksheet(\"Followings\")\n",
    "old_followings = gd.get_as_dataframe(ws)\n",
    "old_followings = old_followings.dropna(axis=1, how='all')\n",
    "old_followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_followings[\"ShivAroor\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gc.open(\"trackfounders\").worksheet(\"Designation\")\n",
    "designation = gd.get_as_dataframe(ws)\n",
    "designation = designation.dropna(axis=1, how='all')\n",
    "designation = designation.dropna(axis=0, how='all')\n",
    "designation.drop_duplicates(subset = ['usernames'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ShivAroor': 'Founder @Livefist',\n",
       " 'ShekharGupta': 'Founder ThePrint',\n",
       " 'captriturathee': \"Co-founder of 'Flying Beast'\",\n",
       " 'ashutosh83B': 'Co-founder - http://satyahindi.com',\n",
       " 'kunalb11': 'Founder - @CRED_club',\n",
       " 'supriyapaul93': 'Co-Founder & CEO @JoshTalksLive @joshskillsapp',\n",
       " 'deepigoyal': 'Founder - @zomato',\n",
       " 'viraj_sheth': 'Co-founder @MonkEtweets',\n",
       " 'bhash': 'Founder @Olacabs',\n",
       " 'vijayshekhar': 'Founder @Paytm',\n",
       " 'gargashutosh': 'Founder - The Brand Called You, Guardian Pharmacy',\n",
       " 'palakzat': 'Founder - Sublist',\n",
       " 'gauravmunjal': 'Founder - Unacademy Group',\n",
       " 'TheQtiyapaGuy': 'Founder - TVF (TheViralFever)',\n",
       " 'SandeepAgg': 'Founder @letsdroom',\n",
       " 'riteshagar': 'Founder & Group CEO @oyorooms',\n",
       " 'warikoo': 'Entrepreneur, founder http://nearbuy.com',\n",
       " 'NaveenTewari': 'Founder - InMobi, Glance, Roposo',\n",
       " 'paraschopra': 'Founder @wingify',\n",
       " 'deepakabbot': 'Co-founder at http://indiagold.co',\n",
       " 'alokebajpai': 'Founder @ixigo',\n",
       " 'Rahul_J_Mathur': 'Founder & CEO - @VerakInsurance',\n",
       " 'mrgirish': 'Founder & CEO - Freshworks @freshworksinc',\n",
       " 'amitranjan': 'CoFounded @SlideShare',\n",
       " 'rohitkbansal': 'Co-founder @Snapdeal',\n",
       " 'Chikisarkar': 'Publisher & founder of Juggernaut Books',\n",
       " 'ashishkashyap': 'Founder - INDmoney SuperMoneyApp',\n",
       " 'kavinbm': 'Founder & CEO @team_hike',\n",
       " 'harshilmathur': 'Co-Founder & CEO, @razorpay',\n",
       " 'telljeeves': 'Co-founder @UrbanLadder',\n",
       " 'AnshulSushil': 'Co-Founder & CEO @Wizikey',\n",
       " 'Aakriti': 'Co-Founder @Wizikey',\n",
       " 'GabbbarSingh': 'Founder @GingerMonkeyIN',\n",
       " 'Being_Humor': 'Founder @the_fauxy'}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usernames_designation = designation.set_index(\"usernames\")['designation'].to_dict()\n",
    "usernames_designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gc.open(\"trackfounders\").worksheet(\"Description\")\n",
    "old_description = gd.get_as_dataframe(ws)\n",
    "old_description = old_description.dropna(axis=1, how='all')\n",
    "old_description = old_description.dropna(axis=0, how='all')\n",
    "old_description['description'] = old_description['description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = list(designation['usernames'])\n",
    "\n",
    "new_followings = pd.DataFrame()\n",
    "all_description = []\n",
    "all_description_usernames = []\n",
    "id_username = {}\n",
    "\n",
    "for i in usernames:\n",
    "\n",
    "    try:\n",
    "        user = client.get_user(username = i, user_fields = ['description'])\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        continue\n",
    "    \n",
    "    id_username[user.data.id] = user.data.username\n",
    "    \n",
    "    all_following_data = []\n",
    "\n",
    "    for response in tweepy.Paginator(client.get_users_following, \n",
    "                                    user_fields = ['username', 'description'],\n",
    "                                    id = user.data.id,\n",
    "                                    max_results=1000):\n",
    "        all_following_data.append(response)\n",
    "        time.sleep(60)\n",
    "\n",
    "    all_following_usernames = []\n",
    "\n",
    "    try:  \n",
    "        for k in all_following_data:\n",
    "            for l in k.data:\n",
    "                all_following_usernames.append(l.username)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        # print(all_following_data)\n",
    "        continue\n",
    "\n",
    "    all_description.append(user.data.description)\n",
    "    all_description_usernames.append(i)\n",
    "\n",
    "    new_followings = pd.merge(new_followings, pd.DataFrame(all_following_usernames, columns=[i]), left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_description = pd.DataFrame({\"usernames\": all_description_usernames, \"description\": all_description})\n",
    "new_description['description'] = new_description['description'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.service_account(filename='creds.json')\n",
    "ws = gc.open(\"trackfounders\").worksheet(\"Posting Date\")\n",
    "posting_date = gd.get_as_dataframe(ws)\n",
    "posting_date = posting_date.dropna(axis=1, how='all')\n",
    "posting_date = posting_date.dropna(axis=0, how='all')\n",
    "posting_date['day'] = posting_date['day'].astype(int)\n",
    "posting_date.drop_duplicates(subset = ['usernames'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames_posting_date = posting_date.set_index(\"usernames\")['day'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_engagement = []\n",
    "all_engagement_score = {}\n",
    "\n",
    "for user_ids in list(id_username.keys()):\n",
    "\n",
    "    username_eng = id_username.get(user_ids)\n",
    "\n",
    "    if usernames_posting_date.get(username_eng) == datetime.today().weekday():\n",
    "\n",
    "        all_tweets = get_all_tweets(user_ids)\n",
    "        \n",
    "        if all_tweets[0].data is not None:\n",
    "\n",
    "            result = get_all_tweets_info(all_tweets)\n",
    "\n",
    "            for data in result:\n",
    "                data['engagement'] = data['likes'] + data['replies'] + data['retweets'] + data['quote_count']\n",
    "            \n",
    "            df = pd.DataFrame(result)\n",
    "\n",
    "            if df['engagement'].max() > 20:\n",
    "                \n",
    "                df_max_engagement = df[df['engagement'] == df['engagement'].max()]\n",
    "                \n",
    "                most_eng_tweet_ids = list(df_max_engagement['tweet_id'])\n",
    "\n",
    "                most_eng_tweet_username = list(df_max_engagement['username'])\n",
    "\n",
    "                for k,j in zip(most_eng_tweet_ids, most_eng_tweet_username):\n",
    "                    all_tweets_engagement.append({j:k})\n",
    "                    all_engagement_score[j] = df['engagement'].max()\n",
    "\n",
    "            # for k,j in zip(most_eng_tweet_ids, most_eng_tweet_username):\n",
    "            #     all_tweets_engagement.append({j:k})            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Followings\n",
    "\n",
    "for i in old_followings.columns:\n",
    "    if i in new_followings.columns:\n",
    "        for j in [x for x in list(set(new_followings[i].astype(str)) - set(old_followings[i].astype(str))) if x == x]:\n",
    "            if usernames_designation.get(i) is None:\n",
    "                # client.create_tweet(text = f\"✅@{i} is now following @{j}\")\n",
    "                print(f\"✅@{i} is now following @{j}\")\n",
    "            else:\n",
    "                # client.create_tweet(text = f\"✅@{i} ({usernames_designation.get(i)}) is now following @{j}\")\n",
    "                print(f\"✅@{i} ({usernames_designation.get(i)}) is now following @{j}\")\n",
    "            # client.create_tweet(text = f\"@{i} is now following @{j}\")\n",
    "            time.sleep(random.randint(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Engaged\n",
    "\n",
    "for i in all_tweets_engagement:\n",
    "    tweet_url = f\"https://twitter.com/{list(i.keys())[0]}/status/{str(list(i.values())[0])}\"\n",
    "    username = list(i.keys())[0]\n",
    "    client.create_tweet(text = f\"🏅 Most Enagaged Tweet of @{username} ({usernames_designation.get(username)}) in the last 10 days:\\n\\nTotal Engagement Score: {all_engagement_score.get(username)}\\n\\n{tweet_url}\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in all_tweets_engagement:\n",
    "#     tweet_url = f\"https://twitter.com/{list(i.values())[0]}/status/{str(list(i.keys())[0])}\"\n",
    "#     username = {list(i.values())[0]}\n",
    "#     print(tweet_url, username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in all_tweets_engagement:\n",
    "#     print(list(i.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # New Unollowings\n",
    "\n",
    "# for i in old_followings.columns:\n",
    "#     if i in new_followings.columns:\n",
    "#         for j in [x for x in list(set(old_followings[i]) - set(new_followings[i])) if x == x]:\n",
    "#             if usernames_designation.get(i) is None:\n",
    "#                 client.create_tweet(text = f\"💔@{i} is no longer following @{j}\")\n",
    "#                 # print(f\"💔@{i} is no longer following @{j}\")\n",
    "#             else:\n",
    "#                 client.create_tweet(text = f\"💔@{i} ({usernames_designation.get(i)}) is no longer following @{j}\")\n",
    "#                 # print(f\"💔@{i} ({usernames_designation.get(i)}) is no longer following @{j}\")\n",
    "#             # client.create_tweet(text = f\"@{i} is now following @{j}\")\n",
    "#             time.sleep(random.randint(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_description = pd.merge(old_description, new_description, on = \"usernames\")\n",
    "compare_description.columns = ['usernames', 'old_description', 'new_description']\n",
    "compare_description['ratio'] = compare_description.apply(lambda x: fuzz.ratio(str(x['old_description'].lower()),str(x['new_description'].lower())), axis = 1)\n",
    "compare_description['ratio'] = compare_description['ratio'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in zip(compare_description['usernames'], compare_description['new_description'], compare_description['ratio']):\n",
    "    if k < 90:\n",
    "        client.create_tweet(text = f\"Updated bio of @{i}: {j}\")\n",
    "        time.sleep(random.randint(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gc.open(\"trackfounders\").worksheet(\"Followings\")\n",
    "ws.clear()\n",
    "gd.set_with_dataframe(ws, new_followings)\n",
    "time.sleep(random.randint(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = gc.open(\"trackfounders\").worksheet(\"Description\")\n",
    "ws.clear()\n",
    "gd.set_with_dataframe(ws, new_description)\n",
    "time.sleep(random.randint(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e6e71039678dc7652134259ab9c4aeb670039fc42bbd0867810ed67d242f6c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
